{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f0ad8d",
   "metadata": {},
   "source": [
    "# ML Zoomcamp 2025 — Week 03: Classification Homework\n",
    "\n",
    "This notebook solves the homework in `cohorts/2025/03-classification/homework.md`.\n",
    "\n",
    "Dataset: Bank Marketing (course lead scoring)\\n\n",
    "- URL: https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1fcb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7ae531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1462, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_URL = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'\n",
    "DATA_FILE = 'course_lead_scoring.csv'\n",
    "\n",
    "if os.path.exists(DATA_FILE):\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_URL)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f'Failed to load dataset from URL. If offline, download {DATA_URL} to {DATA_FILE}. Error: {e}')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27441643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per feature (after filling):\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "target = 'converted'\n",
    "assert target in df.columns, f'Missing target column {target}'\n",
    "\n",
    "# Identify feature columns\n",
    "feature_cols = [c for c in df.columns if c != target]\n",
    "\n",
    "# Split features by type\n",
    "numeric_cols = df[feature_cols].select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_cols = df[feature_cols].select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "# Fill missing values per instructions\n",
    "if categorical_cols:\n",
    "    df[categorical_cols] = df[categorical_cols].fillna('NA')\n",
    "if numeric_cols:\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(0.0)\n",
    "\n",
    "# Quick NA check (features only)\n",
    "na_counts = df[feature_cols].isna().sum().sort_values(ascending=False)\n",
    "print('Missing values per feature (after filling):')\n",
    "print(na_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c55b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 — Mode of industry: retail\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Mode of industry\n",
    "industry_mode = df['industry'].mode(dropna=False)[0] if 'industry' in df.columns else None\n",
    "print('Q1 — Mode of industry:', industry_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c3ba55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 — Pair with highest correlation among given: ('annual_income', 'interaction_count')\n",
      "Correlations: {'interaction_count & lead_score': 0.009888182496913105, 'number_of_courses_viewed & lead_score': -0.004878998354681265, 'number_of_courses_viewed & interaction_count': -0.023565222882888055, 'annual_income & interaction_count': 0.027036472404814396}\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Correlation matrix (numerical) and specified pairs\n",
    "corr = df[numeric_cols].corr(numeric_only=True) if numeric_cols else pd.DataFrame()\n",
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count'),\n",
    "]\n",
    "\n",
    "def corr_for(a, b):\n",
    "    if a in corr.columns and b in corr.columns:\n",
    "        return corr.loc[a, b]\n",
    "    return np.nan\n",
    "\n",
    "corr_results = {}\n",
    "for a, b in pairs:\n",
    "    corr_ab = corr_for(a, b)\n",
    "    corr_results[(a, b)] = corr_ab\n",
    "\n",
    "best_pair = max(corr_results.items(), key=lambda kv: (0 if pd.isna(kv[1]) else abs(kv[1])))[0]\n",
    "print('Q2 — Pair with highest correlation among given:', best_pair)\n",
    "print('Correlations:', {f'{a} & {b}': None if pd.isna(v) else float(v) for (a,b), v in corr_results.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3900bcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (877, 8) (292, 8) (293, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split the data: 60/20/20 (train/val/test)\n",
    "X = df[feature_cols].copy()\n",
    "y_raw = df[target]\n",
    "try:\n",
    "    y = y_raw.astype(int).values\n",
    "except Exception:\n",
    "    y_num = pd.to_numeric(y_raw, errors='coerce')\n",
    "    if y_num.isna().any():\n",
    "        y = y_raw.astype(str).str.lower().map({'yes':1, 'no':0, 'true':1, 'false':0, '1':1, '0':0}).astype(int).values\n",
    "    else:\n",
    "        y = y_num.astype(int).values\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print('Shapes:', X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "386fafef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 — MI scores (train, categorical, rounded to 2):\n",
      "{'industry': 0.02, 'location': 0.0, 'lead_source': 0.03, 'employment_status': 0.02}\n",
      "Q3 — Variable with biggest MI among options: lead_source\n"
     ]
    }
   ],
   "source": [
    "# Question 3: Mutual information (train, categorical features)\n",
    "cat_cols_train = [c for c in categorical_cols if c in X_train.columns]\n",
    "mi_scores = {}\n",
    "for col in cat_cols_train:\n",
    "    x, _ = pd.factorize(X_train[col])\n",
    "    x = x.reshape(-1, 1)\n",
    "    mi = mutual_info_classif(x, y_train, discrete_features=True, random_state=42)[0]\n",
    "    mi_scores[col] = mi\n",
    "\n",
    "mi_scores_rounded = {k: round(float(v), 2) for k, v in mi_scores.items()}\n",
    "options_q3 = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "present_q3 = [c for c in options_q3 if c in mi_scores]\n",
    "best_q3 = max(present_q3, key=lambda c: mi_scores[c]) if present_q3 else None\n",
    "\n",
    "print('Q3 — MI scores (train, categorical, rounded to 2):')\n",
    "print({k: mi_scores_rounded.get(k, None) for k in options_q3})\n",
    "print('Q3 — Variable with biggest MI among options:', best_q3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "824416e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 — Validation accuracy (rounded to 2): 0.74\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Logistic Regression with one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', [c for c in numeric_cols if c in X_train.columns]),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), [c for c in categorical_cols if c in X_train.columns]),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "clf = Pipeline(steps=[('preprocess', preprocessor), ('lr', lr)])\n",
    "clf.fit(X_train, y_train)\n",
    "val_pred = clf.predict(X_val)\n",
    "acc_val = accuracy_score(y_val, val_pred)\n",
    "print('Q4 — Validation accuracy (rounded to 2):', round(acc_val, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee64a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 — Baseline val acc: 0.7431506849315068\n",
      "Q5 — Acc without feature and differences: {'industry': {'acc_wo': 0.7432, 'diff': 0.0}, 'employment_status': {'acc_wo': 0.7466, 'diff': -0.0034}, 'lead_score': {'acc_wo': 0.7432, 'diff': 0.0}}\n",
      "Q5 — Feature with smallest difference: employment_status\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Feature elimination (difference = baseline - acc_without_feature)\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "\n",
    "def train_val_acc_dropping(feature_to_drop=None):\n",
    "    num_cols = [c for c in numeric_cols if c in X_train.columns and c != feature_to_drop]\n",
    "    cat_cols = [c for c in categorical_cols if c in X_train.columns and c != feature_to_drop]\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', num_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "    model = Pipeline(steps=[('preprocess', pre), ('lr', LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42))])\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    return accuracy_score(y_val, preds)\n",
    "\n",
    "baseline_acc = acc_val\n",
    "drop_results = {}\n",
    "for f in features_to_test:\n",
    "    acc_wo = train_val_acc_dropping(f)\n",
    "    diff = baseline_acc - acc_wo\n",
    "    drop_results[f] = {'acc_wo': acc_wo, 'diff': diff}\n",
    "\n",
    "smallest_diff_feature = min(drop_results.items(), key=lambda kv: kv[1]['diff'])[0]\n",
    "print('Q5 — Baseline val acc:', baseline_acc)\n",
    "print('Q5 — Acc without feature and differences:', {k: {'acc_wo': round(v['acc_wo'], 4), 'diff': round(v['diff'], 4)} for k, v in drop_results.items()})\n",
    "print('Q5 — Feature with smallest difference:', smallest_diff_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce27665b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6 — Validation accuracies (rounded to 3): {0.01: 0.743, 0.1: 0.743, 1: 0.743, 10: 0.743, 100: 0.743}\n",
      "Q6 — Best C: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Question 6: Regularized logistic regression sweep over C\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "val_scores = {}\n",
    "for c in C_values:\n",
    "    lr_c = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    pipe_c = Pipeline(steps=[('preprocess', preprocessor), ('lr', lr_c)])\n",
    "    pipe_c.fit(X_train, y_train)\n",
    "    pred_c = pipe_c.predict(X_val)\n",
    "    acc_c = accuracy_score(y_val, pred_c)\n",
    "    val_scores[c] = acc_c\n",
    "\n",
    "val_scores_rounded = {c: round(float(acc), 3) for c, acc in val_scores.items()}\n",
    "best_acc = max(val_scores.values())\n",
    "best_candidates = [c for c, acc in val_scores.items() if acc == best_acc]\n",
    "best_c = min(best_candidates)\n",
    "print('Q6 — Validation accuracies (rounded to 3):', val_scores_rounded)\n",
    "print('Q6 — Best C:', best_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0979bb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1_mode_industry': 'retail',\n",
       " 'Q2_best_pair': ('annual_income', 'interaction_count'),\n",
       " 'Q3_best_mi_var': 'lead_source',\n",
       " 'Q4_val_accuracy_2dp': 0.74,\n",
       " 'Q5_smallest_diff_feature': 'employment_status',\n",
       " 'Q6_best_C': 0.01}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of answers\n",
    "answers = {\n",
    "    'Q1_mode_industry': industry_mode,\n",
    "    'Q2_best_pair': best_pair,\n",
    "    'Q3_best_mi_var': best_q3,\n",
    "    'Q4_val_accuracy_2dp': round(acc_val, 2),\n",
    "    'Q5_smallest_diff_feature': smallest_diff_feature,\n",
    "    'Q6_best_C': best_c,\n",
    "}\n",
    "answers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
