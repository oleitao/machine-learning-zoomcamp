{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64b0c32",
   "metadata": {},
   "source": [
    "# Homework 06 — Trees and Ensembles (Solutions)\n",
    "\n",
    "This notebook implements the solution to `cohorts/2025/06-trees/homework.md` using the Car Fuel Efficiency dataset.\n",
    "\n",
    "Target: predict `fuel_efficiency_mpg`.\n",
    "\n",
    "General steps:\n",
    "- Load data and fill missing values with 0.\n",
    "- Split 60%/20%/20% with `random_state=1`.\n",
    "- Vectorize with `DictVectorizer(sparse=True)`.\n",
    "- Answer Q1–Q6 with reproducible code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1119da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RANDOM_STATE = 1\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcdd031",
   "metadata": {},
   "source": [
    "## Data loading and preparation\n",
    "- Read the CSV locally if present, otherwise load from the URL.\n",
    "- Fill missing values with 0 (as per assignment).\n",
    "- Identify the target column (ideally `fuel_efficiency_mpg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9a76ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fuel_efficiency_mpg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_URL = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv'\n",
    "DATA_PATH = 'car_fuel_efficiency.csv'\n",
    "\n",
    "# Load dataset (local or remote)\n",
    "if os.path.exists(DATA_PATH):\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "else:\n",
    "    # If you prefer, download first with `wget` as in the assignment.\n",
    "    df = pd.read_csv(DATA_URL)\n",
    "\n",
    "# Fill missing values with 0\n",
    "df = df.copy()\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Identify preferred target column\n",
    "target_candidates = [\"fuel_efficiency_mpg\", \"combined_mpg\", \"fuel_efficiency\"]\n",
    "target = None\n",
    "for c in target_candidates:\n",
    "    if c in df.columns:\n",
    "        target = c\n",
    "        break\n",
    "if target is None:\n",
    "    # Fallback: search for a column with 'mpg' or 'efficien' in the name\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if 'mpg' in cl or 'efficien' in cl:\n",
    "            target = c\n",
    "            break\n",
    "\n",
    "assert target is not None, 'Could not find the target column (MPG/efficiency).'\n",
    "target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee084f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5822, 1941, 1941)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split 60/20/20 with random_state=1\n",
    "df_full = df.copy()\n",
    "y = df_full[target].values\n",
    "X = df_full.drop(columns=[target])\n",
    "\n",
    "# First: hold out 20% for test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "# Then: from the remaining 80%, hold out 25% for validation -> 0.8 * 0.25 = 0.2\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE)\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efebbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5822, 14), (1941, 14), (1941, 14))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorization with DictVectorizer(sparse=True)\n",
    "dv = DictVectorizer(sparse=True)\n",
    "\n",
    "train_dicts = X_train.to_dict(orient='records')\n",
    "val_dicts   = X_val.to_dict(orient='records')\n",
    "test_dicts  = X_test.to_dict(orient='records')\n",
    "\n",
    "X_train_dv = dv.fit_transform(train_dicts)\n",
    "X_val_dv   = dv.transform(val_dicts)\n",
    "X_test_dv  = dv.transform(test_dicts)\n",
    "\n",
    "X_train_dv.shape, X_val_dv.shape, X_test_dv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc36b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def base_name(feat_name):\n",
    "    # Aggregate DV feature names (e.g., 'origin=Asia' -> 'origin')\n",
    "    return feat_name.split('=')[0] if isinstance(feat_name, str) else feat_name\n",
    "\n",
    "def pick_first_available(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0206db",
   "metadata": {},
   "source": [
    "## Q1 — Decision tree (max_depth=1)\n",
    "Train a `DecisionTreeRegressor(max_depth=1)` and identify the feature used at the root split.\n",
    "\n",
    "Because vectorization expands categories (e.g., `origin=Asia`), we map the root index back to the original feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a0f4a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vehicle_weight', 'vehicle_weight')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=1, random_state=RANDOM_STATE)\n",
    "dt.fit(X_train_dv, y_train)\n",
    "\n",
    "root_idx = dt.tree_.feature[0]  # index of the DV feature\n",
    "root_feat = dv.feature_names_[root_idx]\n",
    "root_base = base_name(root_feat)\n",
    "root_feat, root_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b31073",
   "metadata": {},
   "source": [
    "Answer (Q1): the feature used at the root is printed in `root_base`.\n",
    "Select the corresponding option (`vehicle_weight`, `model_year`, `origin`, or `fuel_type`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4669b64b",
   "metadata": {},
   "source": [
    "## Q2 — Random Forest (n_estimators=10)\n",
    "Train `RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)` and compute RMSE on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e51211b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4586615458484907"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf10 = RandomForestRegressor(n_estimators=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf10.fit(X_train_dv, y_train)\n",
    "val_pred = rf10.predict(X_val_dv)\n",
    "rmse_q2 = rmse(y_val, val_pred)\n",
    "rmse_q2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0773c6b",
   "metadata": {},
   "source": [
    "Answer (Q2): choose among 0.045, 0.45, 4.5 or 45.0 the closest to `rmse_q2`.\n",
    "(Typically, realistic values here are around 4–5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5490cc",
   "metadata": {},
   "source": [
    "## Q3 — Effect of n_estimators (10 → 200)\n",
    "Vary `n_estimators` from 10 to 200 (step 10), `random_state=1`, evaluate on validation and find after which value RMSE stops improving (3 decimal places)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f107e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(10, 0.4586615458484907),\n",
       "  (20, 0.4536799102144079),\n",
       "  (30, 0.4511716029987014),\n",
       "  (40, 0.4483573590280684),\n",
       "  (50, 0.446179229382576)],\n",
       " 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = list(range(10, 201, 10))\n",
    "rmse_by_n = []\n",
    "\n",
    "for n in vals:\n",
    "    model = RandomForestRegressor(n_estimators=n, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    model.fit(X_train_dv, y_train)\n",
    "    pred = model.predict(X_val_dv)\n",
    "    r = rmse(y_val, pred)\n",
    "    rmse_by_n.append(r)\n",
    "\n",
    "list(zip(vals, rmse_by_n))[:5], len(rmse_by_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0750433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.443, 150)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the last point where RMSE (rounded to 3 decimals) improves\n",
    "best_rmse_round3 = float('inf')\n",
    "last_improving_n = vals[0]\n",
    "rmse_round3 = [round(x, 3) for x in rmse_by_n]\n",
    "\n",
    "for n, r in zip(vals, rmse_round3):\n",
    "    if r < best_rmse_round3:\n",
    "        best_rmse_round3 = r\n",
    "        last_improving_n = n\n",
    "\n",
    "best_rmse_round3, last_improving_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530481ff",
   "metadata": {},
   "source": [
    "Answer (Q3): `last_improving_n` (if it never stops improving up to 200, answer 200)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1376f53",
   "metadata": {},
   "source": [
    "## Q4 — Best max_depth by mean RMSE\n",
    "For each `max_depth` in `[10, 15, 20, 25]`, compute the mean RMSE on validation by sweeping `n_estimators` from 10 to 200 (step 10). Choose the `max_depth` with the lowest mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1616b126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 0.44187929925252156,\n",
       " 15: 0.44561628816456206,\n",
       " 20: 0.4456793443309614,\n",
       " 25: 0.44570249863475137}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths = [10, 15, 20, 25]\n",
    "mean_rmse_by_depth = {}\n",
    "\n",
    "for d in depths:\n",
    "    rmses = []\n",
    "    for n in vals:\n",
    "        model = RandomForestRegressor(n_estimators=n, max_depth=d, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        model.fit(X_train_dv, y_train)\n",
    "        pred = model.predict(X_val_dv)\n",
    "        rmses.append(rmse(y_val, pred))\n",
    "    mean_rmse_by_depth[d] = float(np.mean(rmses))\n",
    "\n",
    "mean_rmse_by_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "833e4142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 0.44187929925252156)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_depth = min(mean_rmse_by_depth, key=mean_rmse_by_depth.get)\n",
    "best_depth, mean_rmse_by_depth[best_depth]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5068f",
   "metadata": {},
   "source": [
    "Answer (Q4): `best_depth` among 10, 15, 20, 25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a873696",
   "metadata": {},
   "source": [
    "## Q5 — Feature importances (Random Forest)\n",
    "Train `RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)` and inspect `feature_importances_`.\n",
    "\n",
    "Since `DictVectorizer` creates multiple columns for categories, aggregate importance by base feature name (before `=`) and compare among:\n",
    "`vehicle_weight`, `horsepower`, `acceleration`, and `engine_displacement`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efa6d5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vehicle_weight': 0.9591531737242687,\n",
       " 'horsepower': 0.01606583100118693,\n",
       " 'acceleration': 0.011489660517019416,\n",
       " 'engine_displacement': 0.0032794702827490425}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_imp = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_imp.fit(X_train_dv, y_train)\n",
    "\n",
    "feat_names = dv.feature_names_\n",
    "importances = rf_imp.feature_importances_\n",
    "\n",
    "# Aggregate by base name\n",
    "agg = {}\n",
    "for fn, imp in zip(feat_names, importances):\n",
    "    b = base_name(fn)\n",
    "    agg[b] = agg.get(b, 0.0) + float(imp)\n",
    "\n",
    "# Candidates (with possible synonyms)\n",
    "cands = {\n",
    "    'vehicle_weight': ['vehicle_weight', 'weight', 'curb_weight'],\n",
    "    'horsepower': ['horsepower', 'engine_hp', 'engine_power'],\n",
    "    'acceleration': ['acceleration'],\n",
    "    'engine_displacement': ['engine_displacement', 'displacement']\n",
    "}\n",
    "\n",
    "cand_scores = {}\n",
    "for key, aliases in cands.items():\n",
    "    score = 0.0\n",
    "    for a in aliases:\n",
    "        score += agg.get(a, 0.0)\n",
    "    cand_scores[key] = score\n",
    "\n",
    "cand_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ebc91a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vehicle_weight', 0.9591531737242687)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_important = max(cand_scores, key=cand_scores.get)\n",
    "most_important, cand_scores[most_important]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48069dc7",
   "metadata": {},
   "source": [
    "Answer (Q5): `most_important` among the 4 options provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34793b",
   "metadata": {},
   "source": [
    "## Q6 — XGBoost: compare eta=0.3 vs 0.1\n",
    "Train for 100 rounds with the given parameters, create `DMatrix` for train and validation, a `watchlist`, and compare validation RMSE for `eta=0.3` and `eta=0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224d2a7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "xgboost is not installed. Install with `pip install xgboost`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Repos/DataTalks.Club/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages/xgboost/__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Repos/DataTalks.Club/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages/xgboost/tracker.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, _deprecate_positional_args, make_jcargs\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Repos/DataTalks.Club/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages/xgboost/core.py:308\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m _LIB = \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Repos/DataTalks.Club/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages/xgboost/core.py:270\u001b[39m, in \u001b[36m_load_lib\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    269\u001b[39m         libname = os.path.basename(lib_paths[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[32m    271\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[33mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) could not be loaded.\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[33mLikely causes:\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[33m  * OpenMP runtime is not installed\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[33m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[33m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[33m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[33m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[32m    279\u001b[39m \n\u001b[32m    280\u001b[39m \u001b[33m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[32m    281\u001b[39m \n\u001b[32m    282\u001b[39m \u001b[33mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    284\u001b[39m         )\n\u001b[32m    285\u001b[39m     _register_log_callback(lib)\n",
      "\u001b[31mXGBoostError\u001b[39m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/oleitao/Documents/Repos/DataTalks.Club/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <B111F8D5-6AC6-3245-A6B5-94693F6992AB> /Users/oleitao/Documents/Repos/DataTalks.Club/machine-learning-zoomcamp/.venv/lib/python3.13/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mxgboost is not installed. Install with `pip install xgboost`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m dtrain = xgb.DMatrix(X_train_dv, label=y_train)\n\u001b[32m     10\u001b[39m dval   = xgb.DMatrix(X_val_dv,   label=y_val)\n",
      "\u001b[31mRuntimeError\u001b[39m: xgboost is not installed. Install with `pip install xgboost`."
     ]
    }
   ],
   "source": [
    "# Install xgboost if needed (uncomment on your machine)\n",
    "# %pip install xgboost\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"xgboost is not installed. Install with `pip install xgboost`.\")\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_dv, label=y_train)\n",
    "dval   = xgb.DMatrix(X_val_dv,   label=y_val)\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "base_params = {\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "def train_and_eval(eta):\n",
    "    params = dict(base_params)\n",
    "    params['eta'] = eta\n",
    "    booster = xgb.train(params, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=False)\n",
    "    pred = booster.predict(dval)\n",
    "    return rmse(y_val, pred)\n",
    "\n",
    "rmse_eta_03 = train_and_eval(0.3)\n",
    "rmse_eta_01 = train_and_eval(0.1)\n",
    "rmse_eta_03, rmse_eta_01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37417830",
   "metadata": {},
   "source": [
    "Answer (Q6): choose `0.3`, `0.1` or `Both` depending on which RMSE (`rmse_eta_03` vs `rmse_eta_01`) is smaller (or if they are equal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c2735",
   "metadata": {},
   "source": [
    "## Answer Summary\n",
    "This cell selects the final options based on the computed results above. If Q6 fails due to missing OpenMP on macOS, install it (see the note below) and re-run the XGBoost cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73474b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1_feature': 'vehicle_weight',\n",
       " 'Q2_RMSE': 0.4586615458484907,\n",
       " 'Q2_choice': 0.45,\n",
       " 'Q3_last_improving_n': 150,\n",
       " 'Q3_choice': 200,\n",
       " 'Q4_best_max_depth': 10,\n",
       " 'Q5_most_important': 'vehicle_weight',\n",
       " 'Q6_best_eta': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1: feature used at the root\n",
    "q1_answer = root_base  # one of: 'vehicle_weight', 'model_year', 'origin', 'fuel_type'\n",
    "\n",
    "# Q2: RF(10) RMSE -> choose closest among [0.045, 0.45, 4.5, 45.0]\n",
    "q2_options = [0.045, 0.45, 4.5, 45.0]\n",
    "q2_choice = min(q2_options, key=lambda x: abs(x - rmse_q2))\n",
    "\n",
    "# Q3: last improving n_estimators -> choose closest among [10, 25, 80, 200]\n",
    "q3_options = [10, 25, 80, 200]\n",
    "q3_choice = min(q3_options, key=lambda x: abs(x - last_improving_n))\n",
    "\n",
    "# Q4: best max_depth among [10, 15, 20, 25]\n",
    "q4_choice = best_depth\n",
    "\n",
    "# Q5: most important feature among the four listed\n",
    "q5_answer = most_important\n",
    "\n",
    "# Q6: try to compute; if not available, leave None\n",
    "q6_answer = None\n",
    "try:\n",
    "    _ = rmse_eta_03; _ = rmse_eta_01\n",
    "    q6_answer = '0.3' if rmse_eta_03 < rmse_eta_01 else ('0.1' if rmse_eta_01 < rmse_eta_03 else 'Both')\n",
    "except Exception:\n",
    "    try:\n",
    "        import xgboost as xgb  # noqa: F401\n",
    "    except Exception:\n",
    "        q6_answer = None\n",
    "\n",
    "answers = {\n",
    "    'Q1_feature': q1_answer,\n",
    "    'Q2_RMSE': float(rmse_q2),\n",
    "    'Q2_choice': q2_choice,\n",
    "    'Q3_last_improving_n': int(last_improving_n),\n",
    "    'Q3_choice': int(q3_choice),\n",
    "    'Q4_best_max_depth': int(q4_choice),\n",
    "    'Q5_most_important': q5_answer,\n",
    "    'Q6_best_eta': q6_answer,\n",
    "}\n",
    "answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254f6bb",
   "metadata": {},
   "source": [
    "### Note on XGBoost on macOS\n",
    "If you see an error about `libomp.dylib`, install the OpenMP runtime and re-run Q6:\n",
    "- Homebrew: `brew install libomp`\n",
    "- Or use a Conda environment where `xgboost` comes with OpenMP support\n",
    "\n",
    "After installation, restart the kernel and execute the Q6 cells."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
