{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10596dd4",
   "metadata": {},
   "source": [
    "# ML Zoomcamp 2025 - Homework 8\n",
    "\n",
    "Hair type classification with a small CNN in PyTorch.\n",
    "\n",
    "Follow the steps in this notebook to train the model and compute the quantities needed to answer questions 1–6 in `homework.md`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6efc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da4859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting hair type dataset...\n",
      "--2025-11-26 00:23:40--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
      "A resolver github.com (github.com)... 140.82.121.4\n",
      "A ligar a github.com (github.com)|140.82.121.4|:443... ligado.\n",
      "Pedido HTTP enviado, a aguardar resposta... 302 Found\n",
      "Localização: https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-26T01%3A21%3A25Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-26T00%3A21%3A00Z&ske=2025-11-26T01%3A21%3A25Z&sks=b&skv=2018-11-09&sig=L4cXsNmLSWgiFlrrCUrA3Te80lmYvRvyDVPuzPExxP8%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDExODQyMSwibmJmIjoxNzY0MTE2NjIxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.QpeZWbcDZ5qR1j1rq4nkwmJSMx3QUsFKJp-IIpmq4vY&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [a seguir]\n",
      "--2025-11-26 00:23:41--  https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-26T01%3A21%3A25Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-26T00%3A21%3A00Z&ske=2025-11-26T01%3A21%3A25Z&sks=b&skv=2018-11-09&sig=L4cXsNmLSWgiFlrrCUrA3Te80lmYvRvyDVPuzPExxP8%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDExODQyMSwibmJmIjoxNzY0MTE2NjIxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.QpeZWbcDZ5qR1j1rq4nkwmJSMx3QUsFKJp-IIpmq4vY&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
      "A resolver release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "A ligar a release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... ligado.\n",
      "Pedido HTTP enviado, a aguardar resposta... 200 OK\n",
      "Tamanho: 102516572 (98M) [application/octet-stream]\n",
      "A gravar em: \"data.zip\"\n",
      "\n",
      "data.zip            100%[===================>]  97,77M  16,7MB/s    em 5,9s    \n",
      "\n",
      "2025-11-26 00:23:47 (16,7 MB/s) - \"data.zip\" gravado [102516572/102516572]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/train'), PosixPath('data/test'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = Path(\"data\")\n",
    "\n",
    "if not data_root.exists():\n",
    "    print(\"Downloading and extracting hair type dataset...\")\n",
    "    !wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip -O data.zip\n",
    "    !unzip -q data.zip\n",
    "else:\n",
    "    print(f\"Found existing data at {data_root.resolve()}\")\n",
    "\n",
    "train_dir = data_root / \"train\"\n",
    "test_dir = data_root / \"test\"\n",
    "train_dir, test_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe033a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['curly', 'straight']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = (200, 200)\n",
    "batch_size = 20\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "validation_dataset = test_dataset\n",
    "class_names = train_dataset.classes\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0319ee22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HairTypeCNN(\n",
       "  (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=313632, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HairTypeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input shape: (3, 200, 200)\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        # After conv + pool: (32, 99, 99) -> 32 * 99 * 99 features\n",
    "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)  # logits for BCEWithLogitsLoss\n",
    "        return x\n",
    "\n",
    "model = HairTypeCNN().to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e493d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BCEWithLogitsLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.002\n",
       "     maximize: False\n",
       "     momentum: 0.8\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c3f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6462, Acc: 0.6362, Val Loss: 0.6032, Val Acc: 0.6517\n",
      "Epoch 2/10, Loss: 0.5475, Acc: 0.7100, Val Loss: 0.7251, Val Acc: 0.6318\n",
      "Epoch 3/10, Loss: 0.5533, Acc: 0.7250, Val Loss: 0.5991, Val Acc: 0.6716\n",
      "Epoch 4/10, Loss: 0.4802, Acc: 0.7712, Val Loss: 0.6033, Val Acc: 0.6567\n",
      "Epoch 5/10, Loss: 0.4334, Acc: 0.8025, Val Loss: 0.6196, Val Acc: 0.6766\n",
      "Epoch 6/10, Loss: 0.3740, Acc: 0.8325, Val Loss: 0.7371, Val Acc: 0.6766\n",
      "Epoch 7/10, Loss: 0.2721, Acc: 0.8838, Val Loss: 0.9223, Val Acc: 0.6418\n",
      "Epoch 8/10, Loss: 0.2478, Acc: 0.9000, Val Loss: 0.7294, Val Acc: 0.7214\n",
      "Epoch 9/10, Loss: 0.2075, Acc: 0.9200, Val Loss: 0.7523, Val Acc: 0.7015\n",
      "Epoch 10/10, Loss: 0.1494, Acc: 0.9450, Val Loss: 0.7894, Val Acc: 0.7015\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "        f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "        f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d889735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 - loss function: nn.BCEWithLogitsLoss()\n",
      "Q2 - total parameters: 20073473\n"
     ]
    }
   ],
   "source": [
    "# Question 1: loss function used\n",
    "q1_loss_function = 'nn.BCEWithLogitsLoss()'\n",
    "print('Q1 - loss function:', q1_loss_function)\n",
    "\n",
    "# Question 2: total number of parameters in the model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print('Q2 - total parameters:', total_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0057c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 - median training accuracy (no augmentation): 0.8175\n",
      "Q4 - std of training loss (no augmentation): 0.1589676198412134\n"
     ]
    }
   ],
   "source": [
    "acc_no_aug = np.array(history['acc'][:10])\n",
    "loss_no_aug = np.array(history['loss'][:10])\n",
    "\n",
    "train_acc_median = float(np.median(acc_no_aug))\n",
    "train_loss_std = float(np.std(loss_no_aug))\n",
    "\n",
    "print('Q3 - median training accuracy (no augmentation):', train_acc_median)\n",
    "print('Q4 - std of training loss (no augmentation):', train_loss_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5834f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_train_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "augmented_train_dataset = datasets.ImageFolder(train_dir, transform=augmented_train_transforms)\n",
    "train_dataset = augmented_train_dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135bd465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Aug] Epoch 1/10, Loss: 0.7357, Acc: 0.5975, Val Loss: 0.6002, Val Acc: 0.6567\n",
      "[Aug] Epoch 2/10, Loss: 0.5931, Acc: 0.6325, Val Loss: 0.5686, Val Acc: 0.7214\n",
      "[Aug] Epoch 3/10, Loss: 0.5813, Acc: 0.6600, Val Loss: 0.5564, Val Acc: 0.7214\n",
      "[Aug] Epoch 4/10, Loss: 0.5587, Acc: 0.7188, Val Loss: 0.6339, Val Acc: 0.6517\n",
      "[Aug] Epoch 5/10, Loss: 0.5134, Acc: 0.7113, Val Loss: 0.5781, Val Acc: 0.7164\n",
      "[Aug] Epoch 6/10, Loss: 0.5083, Acc: 0.7338, Val Loss: 0.6274, Val Acc: 0.6567\n",
      "[Aug] Epoch 7/10, Loss: 0.5080, Acc: 0.7262, Val Loss: 0.4988, Val Acc: 0.7562\n",
      "[Aug] Epoch 8/10, Loss: 0.5136, Acc: 0.7312, Val Loss: 0.5231, Val Acc: 0.7463\n",
      "[Aug] Epoch 9/10, Loss: 0.5143, Acc: 0.7412, Val Loss: 0.6088, Val Acc: 0.6567\n",
      "[Aug] Epoch 10/10, Loss: 0.5054, Acc: 0.7338, Val Loss: 0.5119, Val Acc: 0.7363\n"
     ]
    }
   ],
   "source": [
    "num_epochs_aug = 10\n",
    "\n",
    "for epoch in range(num_epochs_aug):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(\n",
    "        f\"[Aug] Epoch {epoch + 1}/{num_epochs_aug}, \"\n",
    "        f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "        f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83114be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 - mean test loss (with augmentation): 0.5707233409976485\n",
      "Q6 - avg test accuracy epochs 6-10 (with augmentation): 0.7104477611940299\n"
     ]
    }
   ],
   "source": [
    "# Use only the epochs trained with augmentation (the last 10 entries)\n",
    "val_loss_aug = np.array(history['val_loss'][-10:])\n",
    "val_acc_aug = np.array(history['val_acc'][-10:])\n",
    "\n",
    "test_loss_mean_aug = float(val_loss_aug.mean())\n",
    "test_acc_mean_last5_aug = float(val_acc_aug[-5:].mean())\n",
    "\n",
    "print('Q5 - mean test loss (with augmentation):', test_loss_mean_aug)\n",
    "print('Q6 - avg test accuracy epochs 6-10 (with augmentation):', test_acc_mean_last5_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6612c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for homework submission:\n",
      "Q1: loss function -> nn.BCEWithLogitsLoss()\n",
      "Q2: total parameters -> 20073473\n",
      "Q3: median training accuracy (no aug) -> 0.8175\n",
      "Q4: std of training loss (no aug) -> 0.1589676198412134\n",
      "Q5: mean test loss (with aug) -> 0.5707233409976485\n",
      "Q6: avg test accuracy epochs 6-10 (with aug) -> 0.7104477611940299\n"
     ]
    }
   ],
   "source": [
    "print('Summary for homework submission:')\n",
    "print('Q1: loss function -> nn.BCEWithLogitsLoss()')\n",
    "print('Q2: total parameters ->', total_params)\n",
    "print('Q3: median training accuracy (no aug) ->', train_acc_median)\n",
    "print('Q4: std of training loss (no aug) ->', train_loss_std)\n",
    "print('Q5: mean test loss (with aug) ->', test_loss_mean_aug)\n",
    "print('Q6: avg test accuracy epochs 6-10 (with aug) ->', test_acc_mean_last5_aug)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
